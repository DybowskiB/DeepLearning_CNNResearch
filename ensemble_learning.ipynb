{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBKFC_3U294f"
      },
      "source": [
        "# Deep Learning Project: CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Pa2R9IK3Ccf"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGsgkz563K9X"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import shutil\n",
        "import kagglehub\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIh74b6G3P3-"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2-s1zxz3Tam"
      },
      "outputs": [],
      "source": [
        "use_standard_augmentation = False\n",
        "use_cutmix = False\n",
        "use_fewshot = False\n",
        "\n",
        "seed = 1\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "\n",
        "model_dir = \"/content/ovr_models\"\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnYjfAVJ3XW-"
      },
      "source": [
        "## Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-dS1F7z3XD_",
        "outputId": "9acbf78e-11f1-406c-af63-69d1334b1735"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Use device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0TeDf9c3go_"
      },
      "source": [
        "## Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8MewlXL3iYv"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVuqK9J83lvm"
      },
      "source": [
        "## Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a32_llIT3qQW",
        "outputId": "58a0db7d-c1eb-43b1-eef7-5058674390a6"
      },
      "outputs": [],
      "source": [
        "if use_standard_augmentation:\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    print(\"Using standard augmentation.\")\n",
        "elif use_cutmix:\n",
        "    transform_train = transforms.ToTensor()\n",
        "    print(\"Using cutmix augmentation.\")\n",
        "else:\n",
        "    transform_train = transforms.ToTensor()\n",
        "    print(\"Using no augmentation.\")\n",
        "\n",
        "transform_test = transforms.ToTensor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YHPJlJg3tTe"
      },
      "source": [
        "## Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcO3jGbJ3x3O",
        "outputId": "4b6375e3-e428-46ca-bbc6-336462c33bc2"
      },
      "outputs": [],
      "source": [
        "cinic_path = kagglehub.dataset_download(\"mengcius/cinic10\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsakehYt3_lW"
      },
      "source": [
        "## Init sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4x3TDtL37Q1"
      },
      "outputs": [],
      "source": [
        "train_set = ImageFolder(f\"{cinic_path}/train\", transform=transform_train)\n",
        "valid_set = ImageFolder(f\"{cinic_path}/valid\", transform=transform_test)\n",
        "test_set = ImageFolder(f\"{cinic_path}/test\", transform=transform_test)\n",
        "classes = train_set.classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a--Rd9l4Ce2"
      },
      "source": [
        "## Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yv_ZbuCj4E9N"
      },
      "outputs": [],
      "source": [
        "class ConvolutionalNeuralNetwork(nn.Module):\n",
        "    def __init__(self, conv_layers, fc_layers, n_classes=1, dropout=0.4):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for out_channels, kernel_size in conv_layers:\n",
        "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size, padding=1))\n",
        "            layers.append(nn.BatchNorm2d(out_channels))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.MaxPool2d(2))\n",
        "            in_channels = out_channels\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "\n",
        "        dummy = torch.zeros(1, 3, 32, 32)\n",
        "        with torch.no_grad():\n",
        "            out = self.conv(dummy)\n",
        "        conv_out_dim = out.view(1, -1).shape[1]\n",
        "\n",
        "        fc = []\n",
        "        for size in fc_layers:\n",
        "            fc.append(nn.Linear(conv_out_dim, size))\n",
        "            fc.append(nn.ReLU())\n",
        "            fc.append(nn.Dropout(dropout))\n",
        "            conv_out_dim = size\n",
        "        fc.append(nn.Linear(conv_out_dim, n_classes))\n",
        "        self.fc = nn.Sequential(*fc)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dinm6fbjrmn2"
      },
      "source": [
        "## Cut-mix implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqGcFaWnrqCV"
      },
      "outputs": [],
      "source": [
        "def apply_cutmix(inputs, labels, alpha=1.0):\n",
        "    lam = torch.distributions.Beta(alpha, alpha).sample().item()\n",
        "    rand_index = torch.randperm(inputs.size(0), device=inputs.device)\n",
        "\n",
        "    target_a = labels\n",
        "    target_b = labels[rand_index]\n",
        "\n",
        "    bbx1, bby1, bbx2, bby2 = rand_bbox_torch(inputs.size(), lam, device=inputs.device)\n",
        "    inputs[:, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
        "\n",
        "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (inputs.size(-1) * inputs.size(-2)))\n",
        "\n",
        "    return inputs, target_a, target_b, lam\n",
        "\n",
        "def rand_bbox_torch(size, lam, device='cpu'):\n",
        "    W = size[2]\n",
        "    H = size[3]\n",
        "    cut_rat = torch.sqrt(torch.tensor(1. - lam))\n",
        "    cut_w = (W * cut_rat).int()\n",
        "    cut_h = (H * cut_rat).int()\n",
        "\n",
        "    cx = torch.randint(W, (1,), device=device).item()\n",
        "    cy = torch.randint(H, (1,), device=device).item()\n",
        "\n",
        "    bbx1 = max(cx - cut_w.item() // 2, 0)\n",
        "    bby1 = max(cy - cut_h.item() // 2, 0)\n",
        "    bbx2 = min(cx + cut_w.item() // 2, W)\n",
        "    bby2 = min(cy + cut_h.item() // 2, H)\n",
        "\n",
        "    return bbx1, bby1, bbx2, bby2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ans9UwNW4JT-"
      },
      "source": [
        "## OvR functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KRqP1m64MAS"
      },
      "outputs": [],
      "source": [
        "def create_ovr_dataset(dataset, target_class, max_per_class=None):\n",
        "    data, targets = [], []\n",
        "    count_pos, count_neg = 0, 0\n",
        "    for x, y in dataset:\n",
        "        label = 1 if y == target_class else 0\n",
        "\n",
        "        # jeśli few-shot aktywny i przekroczony limit, pomiń\n",
        "        if max_per_class is not None:\n",
        "            if label == 1 and count_pos >= max_per_class:\n",
        "                continue\n",
        "            if label == 0 and count_neg >= 9 * max_per_class:\n",
        "                continue\n",
        "\n",
        "        data.append(x)\n",
        "        targets.append(label)\n",
        "\n",
        "        if label == 1:\n",
        "            count_pos += 1\n",
        "        else:\n",
        "            count_neg += 1\n",
        "\n",
        "    return TensorDataset(torch.stack(data), torch.tensor(targets))\n",
        "\n",
        "def evaluate_binary_model(model, dataloader):\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = torch.sigmoid(model(inputs).squeeze())\n",
        "            preds = (outputs > 0.5).float()\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    return acc\n",
        "\n",
        "def train_ovr_model(model, data_loader, valid_loader, test_loader, criterion, optimizer, epochs=5):\n",
        "    model.train()\n",
        "    train_accs, valid_accs, test_accs = [], [], []\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        for inputs, labels in data_loader:\n",
        "          inputs, labels = inputs.to(device, non_blocking=True), labels.float().to(device, non_blocking=True)\n",
        "\n",
        "          if use_cutmix:\n",
        "            inputs, target_a, target_b, lam = apply_cutmix(inputs, labels)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(inputs).squeeze()\n",
        "\n",
        "          if use_cutmix:\n",
        "            loss = lam * criterion(outputs, target_a) + (1 - lam) * criterion(outputs, target_b)\n",
        "          else:\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "\n",
        "        train_acc = evaluate_binary_model(model, data_loader)\n",
        "        train_accs.append(train_acc)\n",
        "\n",
        "        valid_acc = evaluate_binary_model(model, valid_loader)\n",
        "        valid_accs.append(valid_acc)\n",
        "\n",
        "        test_acc = evaluate_binary_model(model, test_loader)\n",
        "        test_accs.append(test_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, loss: {(total_loss / len(data_loader)):.4f}, train acc: {train_acc:.4f}, valid acc: {valid_acc:.4f}, test acc: {test_acc:.4f}\")\n",
        "\n",
        "    return train_accs, valid_accs, test_accs\n",
        "\n",
        "def predict_ovr(models, dataloader):\n",
        "    outputs_all = []\n",
        "    for model in models:\n",
        "        model.eval()\n",
        "        preds = []\n",
        "        with torch.no_grad():\n",
        "            for inputs, _ in dataloader:\n",
        "                inputs = inputs.to(device, non_blocking=True)\n",
        "                outputs = torch.sigmoid(model(inputs).squeeze())\n",
        "                preds.append(outputs.cpu())\n",
        "        outputs_all.append(torch.cat(preds).unsqueeze(1))\n",
        "    return torch.cat(outputs_all, dim=1).argmax(dim=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqXPC8coFGWj"
      },
      "source": [
        "## Save model function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vN9vbxkjFJP8"
      },
      "outputs": [],
      "source": [
        "def save_ovr_model(model, class_index):\n",
        "    path = os.path.join(model_dir, f\"model_class_{class_index}.pt\")\n",
        "    torch.save(model.state_dict(), path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Sopsh9l4SSt"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWVUF2aQ4Tuv",
        "outputId": "70dd1300-321c-483d-f517-d63294afdc92"
      },
      "outputs": [],
      "source": [
        "print(\"Training OvR Ensemble...\")\n",
        "ovr_models = []\n",
        "ovr_stats = []\n",
        "conv_arch = [(32, 3), (64, 3)]\n",
        "fc_arch = [128]\n",
        "\n",
        "dataset_to_use = train_set\n",
        "max_per_class=None\n",
        "if use_fewshot:\n",
        "    print(\"Using few-shot: 100 samples per each class\")\n",
        "    max_per_class = 100\n",
        "\n",
        "for i, cls in enumerate(classes):\n",
        "    print(f\"Training model for class {cls}...\")\n",
        "    binary_train = create_ovr_dataset(dataset_to_use, i, max_per_class)\n",
        "    binary_valid = create_ovr_dataset(valid_set, i, None)\n",
        "    binary_test  = create_ovr_dataset(test_set, i, None)\n",
        "\n",
        "    loader = DataLoader(binary_train, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    vloader = DataLoader(binary_valid, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    tloader = DataLoader(binary_test,  batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    model = ConvolutionalNeuralNetwork(conv_arch, fc_arch, n_classes=1, dropout=0.4).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    train_accs, valid_accs, test_accs = train_ovr_model(model, loader, vloader, tloader, criterion, optimizer, epochs=25)\n",
        "    ovr_stats.append((train_accs, valid_accs, test_accs))\n",
        "\n",
        "    # Save model and clean RAM\n",
        "    save_ovr_model(model, i)\n",
        "    del model\n",
        "    del loader\n",
        "    del vloader\n",
        "    del tloader\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoAHQ-cDEWEC"
      },
      "source": [
        "## Load models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b36loaSHEXWq"
      },
      "outputs": [],
      "source": [
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "def load_ovr_models(num_classes, conv_arch, fc_arch):\n",
        "    models = []\n",
        "    for i in range(num_classes):\n",
        "        model = ConvolutionalNeuralNetwork(conv_arch, fc_arch, n_classes=1, dropout=0.4).to(device)\n",
        "        path = os.path.join(model_dir, f\"model_class_{i}.pt\")\n",
        "        model.load_state_dict(torch.load(path, map_location=device))\n",
        "        model.eval()\n",
        "        models.append(model)\n",
        "    return models\n",
        "\n",
        "ovr_models = load_ovr_models(len(classes), conv_arch, fc_arch)\n",
        "print(\"Models loaded for evaluation.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9DXrNSR4a6-"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtdfrrdi4c4d"
      },
      "outputs": [],
      "source": [
        "print(\"\\n Evaluation:\")\n",
        "\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "y_true = []\n",
        "for _, labels in test_loader:\n",
        "    y_true.extend(labels.numpy())\n",
        "\n",
        "y_pred = predict_ovr(ovr_models, test_loader)\n",
        "\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "print(f\"Accuracy OvR ensemble: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7bpJnKp4hCX"
      },
      "source": [
        "## Charts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOnUGbmB4iUl"
      },
      "outputs": [],
      "source": [
        "for i, cls in enumerate(classes):\n",
        "    train_accs, valid_accs, test_accs = ovr_stats[i]\n",
        "    plt.plot(train_accs, label='Train')\n",
        "    plt.plot(valid_accs, label='Valid')\n",
        "    plt.plot(test_accs,  label='Test')\n",
        "    plt.title(f'Accuracy for class: {cls}')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-kwSpmB4kql"
      },
      "source": [
        "## Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIYngaTY4nK1"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "disp.plot(cmap=\"Blues\", xticks_rotation=45)\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8saBnEBG393-"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
